Args: /home/lfr/MLIR_Tutorial/build/15-lowing_to_llvm/src/Tools/NS-opt/NS-opt15 /home/lfr/MLIR_Tutorial/15-lowing_to_llvm/test/Pipeline/to_llvm_pipeline.mlir --north-star-basic-pipeline=DP_Nums=2 --mlir-print-ir-after-all --debug 
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedType)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemRefLayoutAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TypedAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ElementsAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistinctAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ResourceBlobManagerDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeDialectInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineBinaryOpExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineConstantExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineDimExprStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::AffineMapStorage)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::IntegerSetStorage)
Load new dialect in Context builtin
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroSuccessors<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroSuccessors]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoRegionArguments<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoRegionArguments]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NoTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::NoTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SingleBlock<mlir::TypeID::get() [with Trait = mlir::OpTrait::SingleBlock]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OpInvariants<mlir::TypeID::get() [with Trait = mlir::OpTrait::OpInvariants]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BytecodeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::BytecodeOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AffineScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AffineScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsIsolatedFromAbove<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsIsolatedFromAbove]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::SymbolTable<mlir::TypeID::get() [with Trait = mlir::OpTrait::SymbolTable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::SymbolOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpAsmOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::OpAsmOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionKindInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionKindInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasOnlyGraphRegion<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasOnlyGraphRegion]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::ModuleOpGenericAdaptorBase::Properties)
Load new dialect in Context func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectInlinerInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConvertToLLVMPatternInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferizableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AutomaticAllocationScope<mlir::TypeID::get() [with Trait = mlir::OpTrait::AutomaticAllocationScope]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallableOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::CallableOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FunctionOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::FunctionOpInterface::Trait]::Empty>)
Load new dialect in Context north_star
Load new dialect in Context tensor
Load new dialect in Context affine
Load new dialect in Context arith
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithFastMathInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::VectorUnrollOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::InferIntRangeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithIntegerOverflowFlagsInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CastOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::arith::ArithRoundingModeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::BufferDeallocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ValueBoundsOpInterface)
Load new dialect in Context ub
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ub::PoisonAttrInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineMapAccessInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaStartOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineDmaWaitOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::LoopLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineReadOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::affine::AffineWriteOpInterface)
Load new dialect in Context complex
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ShapedDimOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OffsetSizeAndStrideOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::transform::FindPayloadReplacementOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetInsertionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SubsetExtractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataParallelAttr)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ZeroRegions<mlir::TypeID::get() [with Trait = mlir::OpTrait::ZeroRegions]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicOperands<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicOperands]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::func::FuncOp>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ConditionallySpeculatable::Trait<mlir::TypeID::get() [with Trait = mlir::ConditionallySpeculatable::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::AlwaysSpeculatableImplTrait<mlir::TypeID::get() [with Trait = mlir::OpTrait::AlwaysSpeculatableImplTrait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::MemoryEffectOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::MemoryEffectOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::MemRefsNormalizable<mlir::TypeID::get() [with Trait = mlir::OpTrait::MemRefsNormalizable]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RegionBranchTerminatorOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::RegionBranchTerminatorOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ReturnLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ReturnLike]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::IsTerminator<mlir::TypeID::get() [with Trait = mlir::OpTrait::IsTerminator]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DataLayoutSpecInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneResult<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneResult]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::Type>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::Type>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneOperand<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneOperand]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DistributeParallelOp::Trait<mlir::TypeID::get() [with Trait = mlir::DistributeParallelOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SupportedDataParallelismOp::Trait<mlir::TypeID::get() [with Trait = mlir::SupportedDataParallelismOp::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::OpToOpPassAdaptor)
Load new dialect in Context linalg
Load new dialect in Context math
Load new dialect in Context memref
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CopyOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableMemOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAccessorOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PromotableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableAllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ViewLikeOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::bufferization::AllocationOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::RuntimeVerifiableOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestructurableTypeInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::LinalgOp)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ContractionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::ConvolutionOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::FillOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::mesh::ShardingInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::PartialReductionOpInterface)
run in MarkDistributeParallelParametersPass
root op: builtin.module
DPNums: 2
TPNums: 1
EPNums: 0
run out: MarkDistributeParallelParametersPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::detail::PreservedAnalyses::AllAnalysesType)
// -----// IR Dump After MarkDistributeParallelParametersPass (mark-distribute-parallel-parameters) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.softmax"(%arg0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %1 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ApplyDistributeTransformPass
root op: func.func
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::BufferCastOpGenericAdaptorBase::Properties)
Apply DataParallelism to north_star.softmax
Apply DataParallelism to north_star.softmax
run out: ApplyDistributeTransformPass
// -----// IR Dump After ApplyDistributeTransformPass (apply-distribute-transform) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %5 = "north_star.softmax"(%4#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%5, %6) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::VariadicResults<mlir::TypeID::get() [with Trait = mlir::OpTrait::VariadicResults]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DialectFoldInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::ConstantLike<mlir::TypeID::get() [with Trait = mlir::OpTrait::ConstantLike]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e3d0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc635554d0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356de00) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e470) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356edf0) {
  %4:2 = "north_star.buffer_cast"(%3) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
    ** Modified: 'north_star.softmax'(0x5ebc63527580)
    ** Modified: 'north_star.softmax'(0x5ebc6356ed50)
    ** Erase   : 'north_star.buffer_cast'(0x5ebc6356edf0)
    ** Erase   : 'north_star.buffer_cast'(0x5ebc6356e470)
"mlir::north_star::{anonymous}::BufferCastOpFold" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %5 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356de00) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc635554d0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527580) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356ed50) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::BranchOpInterface)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasRecursiveMemoryEffects<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasRecursiveMemoryEffects]::Empty>)

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e3d0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc635554d0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356de00) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527580) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356ed50) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::BufferCastOpFold : 'north_star.buffer_cast -> ()' {
Trying to match "mlir::north_star::{anonymous}::BufferCastOpFold"
"mlir::north_star::{anonymous}::BufferCastOpFold" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
    %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
    return %5 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in DeviceRegionFusionPass
root op: func.func

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %5 = "north_star.buffer_cast"(%3, %4) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356ed50) {
  %4 = "north_star.softmax"(%2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527580) {
  %3 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc6356de00) {
  %2 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc635554d0) {
  %1 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e3d0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::DeviceKernelOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.device_kernel'(0x5ebc6356ede0)
    ** Insert  : 'north_star.return'(0x5ebc63575dc0)
    ** Modified: 'north_star.buffer_cast'(0x5ebc6356ee90)
    ** Insert  : 'north_star.device_kernel'(0x5ebc63575ed0)
    ** Insert  : 'north_star.return'(0x5ebc635760e0)
    ** Modified: 'north_star.buffer_cast'(0x5ebc6356ee90)
"{anonymous}::BufferCastOpDeviceRegionFusion" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
ImplicitTypeIDRegistry::lookupOrInsert(mlir::FusionRegionOpInterfaces::Trait<mlir::TypeID::get() [with Trait = mlir::FusionRegionOpInterfaces::Trait]::Empty>)
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::HasParent<mlir::north_star::DeviceKernelOp>::Impl]::Empty>)
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %8 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.softmax"(%8) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %9 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.softmax"(%0#0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "north_star.softmax"(%0#1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%3) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc635760e0) {
  "north_star.return"(%9) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %7 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc63575dc0) {
  "north_star.return"(%11) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.softmax'(0x5ebc6356ed50)
** Erase   : 'north_star.softmax'(0x5ebc63527580)
** Erase   : 'north_star.softmax'(0x5ebc6356de00)
** Erase   : 'north_star.softmax'(0x5ebc635554d0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc635760e0) {
  "north_star.return"(%5) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63576060) {
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575fd0) {
  %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc63575dc0) {
  "north_star.return"(%7) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575d00) {
  %7 = "north_star.softmax"(%6) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527ae0) {
  %6 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e3d0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpDeviceRegionFusion : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpDeviceRegionFusion"
"{anonymous}::BufferCastOpDeviceRegionFusion" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//
region has changed: true
run out: DeviceRegionFusionPass
// -----// IR Dump After DeviceRegionFusionPass (device-region-fusion) //----- //
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %4 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %5 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %3 : !north_star.ns_tensor<2x128xf32,0>
}

run in EliminateBufferCastPass

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%3) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356ee90) {
  %3 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x5ebc63564610)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::OneTypedResult<mlir::RankedTensorType>::Impl]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::ReifyRankedShapedTypeOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::ReifyRankedShapedTypeOpInterface::Trait]::Empty>)
    ** Insert  : 'tensor.empty'(0x5ebc63576170)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::TensorToNSTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc635554d0)
    ** Insert  : 'north_star.buffer'(0x5ebc6356de00)
    ** Insert  : 'north_star.gather'(0x5ebc635647b0)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::GetTensorOpGenericAdaptorBase::Properties)
    ** Insert  : 'north_star.get_tensor'(0x5ebc63527580)
    ** Replace : 'north_star.buffer_cast'(0x5ebc6356ee90)
    ** Modified: 'func.return'(0x5ebc63527cb0)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %1 = "north_star.device_kernel"(%0#0) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "north_star.device_kernel"(%0#1) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %10 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %4 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %8 = "north_star.buffer_cast"(%1, %2) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %7 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%7) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63527580) {
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5ebc635647b0) {
  "north_star.gather"(%3, %6) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

ImplicitTypeIDRegistry::lookupOrInsert(mlir::OpTrait::NOperands<2>::Impl<mlir::TypeID::get() [with Trait = mlir::OpTrait::NOperands<2>::Impl]::Empty>)
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6356de00) {
  %6 = "north_star.buffer"(%5) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635554d0) {
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63576170) {
  %4 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63564610) {
  %3 = "north_star.buffer"(%1, %2) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc635760e0) {
  "north_star.return"(%10) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63576060) {
  %10 = "north_star.softmax"(%9) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575fd0) {
  %9 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc63575dc0) {
  "north_star.return"(%12) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575d00) {
  %12 = "north_star.softmax"(%11) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527ae0) {
  %11 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer_cast'(0x5ebc6356e3d0) {
  %0:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)


  * Pattern {anonymous}::BufferCastOpToCommunicationPattern : 'north_star.buffer_cast -> ()' {
Trying to match "{anonymous}::BufferCastOpToCommunicationPattern"
    ** Insert  : 'north_star.buffer'(0x5ebc6356ed50)
    ** Insert  : 'tensor.empty'(0x5ebc63564880)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc635761e0)
    ** Insert  : 'tensor.empty'(0x5ebc63576ae0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc63576b50)
    ** Insert  : 'north_star.buffer'(0x5ebc63576be0)
    ** Insert  : 'north_star.scatter'(0x5ebc63576c80)
    ** Insert  : 'north_star.get_tensor'(0x5ebc63576d30)
    ** Insert  : 'north_star.get_tensor'(0x5ebc63576dc0)
    ** Replace : 'north_star.buffer_cast'(0x5ebc6356e3d0)
    ** Modified: 'north_star.device_kernel'(0x5ebc6356ede0)
    ** Modified: 'north_star.device_kernel'(0x5ebc63575ed0)
"{anonymous}::BufferCastOpToCommunicationPattern" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %8:2 = "north_star.buffer_cast"(%arg0) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<2x128xf32,0>) -> (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>)
  %9 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,0>
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %10 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    north_star.return %18 : !north_star.ns_tensor<1x128xf32,1>
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %11 = "north_star.buffer"(%9, %10) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %12 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %14 = "north_star.buffer"(%13) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%11, %14) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %15 = "north_star.get_tensor"(%14) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %16 = "north_star.buffer_cast"(%9, %10) <{distribute_attr = #north_star.DP<DP = 2 : 0, 1>}> : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<2x128xf32,0>
  return %15 : !north_star.ns_tensor<2x128xf32,0>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63576dc0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63576d30) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5ebc63576c80) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63576be0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576b50) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63576ae0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635761e0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63564880) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6356ed50) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
** Erase   : 'north_star.buffer_cast'(0x5ebc6356ee90)
** Erase   : 'north_star.buffer_cast'(0x5ebc6356e3d0)

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%14) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63527580) {
  %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5ebc635647b0) {
  "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6356de00) {
  %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635554d0) {
  %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63576170) {
  %11 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63564610) {
  %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc635760e0) {
  "north_star.return"(%16) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63576060) {
  %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575fd0) {
  %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.return'(0x5ebc63575dc0) {
  "north_star.return"(%18) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63575d00) {
  %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.softmax'(0x5ebc63527ae0) {
  %17 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63576dc0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc63576d30) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5ebc63576c80) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63576be0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576b50) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63576ae0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635761e0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63564880) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63527d30) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6356ed50) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//
run out: EliminateBufferCastPass
// -----// IR Dump After EliminateBufferCastPass (eliminate-buffercast) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %8 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,0>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,0>
    }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "north_star.device_kernel"(%7) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
      %15 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      %16 = "north_star.softmax"(%15) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
      north_star.return %16 : !north_star.ns_tensor<1x128xf32,1>
    }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.buffer"(%8, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %11 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %13 = "north_star.buffer"(%12) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%10, %13) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %14 = "north_star.get_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %14 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in ConvertNorthStarToLinalgPass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x5ebc63524120) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x5ebc63527d30) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc6356ed50) {
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63564880) {
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635761e0) {
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63576ae0) {
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576b50) {
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc63576be0) {
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x5ebc63576c80) {
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63576d30) {
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63576dc0) {
  %7 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5ebc6356ede0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x5ebc6356e3c0)
    ** Insert Block into : 'north_star.device_kernel'(0x5ebc6356e3c0)
    ** Insert  : 'north_star.softmax'(0x5ebc63574430)
    ** Insert  : 'north_star.softmax'(0x5ebc635788f0)
    ** Insert  : 'north_star.return'(0x5ebc635733c0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc63578b40)
    ** Replace : 'north_star.device_kernel'(0x5ebc6356ede0)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc63574430) {
      %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5ebc6357bc30)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::detail::SoftmaxOpGenericAdaptorBase::Properties)
        ** Insert  : 'linalg.softmax'(0x5ebc6357bca0)
        ** Replace : 'north_star.softmax'(0x5ebc63574430)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6357bc30) {
          %23 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357bca0) {
          %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  north_star.return %5 : !north_star.ns_tensor<1x128xf32,0>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5ebc6356e3c0) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc63574430) {
      %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc635788f0) {
      %26 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5ebc6357be20)
        ** Insert  : 'linalg.softmax'(0x5ebc6357be90)
        ** Replace : 'north_star.softmax'(0x5ebc635788f0)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6357be20) {
          %26 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357be90) {
          %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,0> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %5 = tensor.empty() : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  north_star.return %7 : !north_star.ns_tensor<1x128xf32,0>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5ebc635733c0) {
      "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpConvertPattern"
        ** Insert  : 'north_star.return'(0x5ebc635746c0)
        ** Replace : 'north_star.return'(0x5ebc635733c0)
"{anonymous}::ReturnOpConvertPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.return'(0x5ebc635746c0) {
          "north_star.return"(%27) : (tensor<1x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'north_star.device_kernel' failed to verify and will be printed in generic form
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %1 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %2 = "builtin.unrealized_conversion_cast"(%1) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>
  %4 = "linalg.softmax"(%2, %3) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %5 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %6 = "tensor.empty"() : () -> tensor<1x128xf32>
  %7 = "linalg.softmax"(%4, %6) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %8 = "north_star.softmax"(%5) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  "north_star.return"(%7) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%8) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63578b40) {
      %21 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "builtin.unrealized_conversion_cast"(%6) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg3: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %22 = "builtin.unrealized_conversion_cast"(%21) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %26 = "tensor.empty"() : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %10 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: !north_star.ns_tensor<1x128xf32,0>):
    %19 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %11 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %17 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %18 = "north_star.softmax"(%17) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%18) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %12 = "north_star.buffer"(%10, %11) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %13 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %15 = "north_star.buffer"(%14) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%12, %15) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %16 = "north_star.get_tensor"(%15) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5ebc63527ae0) {
  %19 = "north_star.softmax"(%arg2) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5ebc63575d00) {
  %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5ebc63575dc0) {
  "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,0>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5ebc63575ed0) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpConvertPattern"
    ** Insert  : 'north_star.device_kernel'(0x5ebc6357a190)
    ** Insert Block into : 'north_star.device_kernel'(0x5ebc6357a190)
    ** Insert  : 'north_star.softmax'(0x5ebc63578c00)
    ** Insert  : 'north_star.softmax'(0x5ebc6357a240)
    ** Insert  : 'north_star.return'(0x5ebc63578ca0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357a520)
    ** Replace : 'north_star.device_kernel'(0x5ebc63575ed0)
"{anonymous}::DeviceKernelOpConvertPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc63578c00) {
      %22 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5ebc6353cb80)
        ** Insert  : 'linalg.softmax'(0x5ebc6357b740)
        ** Replace : 'north_star.softmax'(0x5ebc63578c00)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6353cb80) {
          %23 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357b740) {
          %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  north_star.return %5 : !north_star.ns_tensor<1x128xf32,1>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5ebc6357a190) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc63578c00) {
      %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.softmax'(0x5ebc6357a240) {
      %26 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.softmax -> ()' {
Trying to match "{anonymous}::SoftmaxOpToLinalgPattern"
        ** Insert  : 'tensor.empty'(0x5ebc6357b850)
        ** Insert  : 'linalg.softmax'(0x5ebc6357b8c0)
        ** Replace : 'north_star.softmax'(0x5ebc6357a240)
"{anonymous}::SoftmaxOpToLinalgPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6357b850) {
          %26 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357b8c0) {
          %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %1 = builtin.unrealized_conversion_cast %0 : !north_star.ns_tensor<1x128xf32,1> to tensor<1x128xf32>
  %2 = tensor.empty() : tensor<1x128xf32>
  %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "north_star.softmax"(%0) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = tensor.empty() : tensor<1x128xf32>
  %6 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%5 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %7 = "north_star.softmax"(%4) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  north_star.return %7 : !north_star.ns_tensor<1x128xf32,1>
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5ebc63578ca0) {
      "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpConvertPattern"
        ** Insert  : 'north_star.return'(0x5ebc63579ec0)
        ** Replace : 'north_star.return'(0x5ebc63578ca0)
"{anonymous}::ReturnOpConvertPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.return'(0x5ebc63579ec0) {
          "north_star.return"(%27) : (tensor<1x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'north_star.device_kernel' failed to verify and will be printed in generic form
%0 = "north_star.device_kernel"(<<UNKNOWN SSA VALUE>>) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %1 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %2 = "builtin.unrealized_conversion_cast"(%1) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %3 = "tensor.empty"() : () -> tensor<1x128xf32>
  %4 = "linalg.softmax"(%2, %3) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %5 = "north_star.softmax"(%1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = "tensor.empty"() : () -> tensor<1x128xf32>
  %7 = "linalg.softmax"(%4, %6) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %8 = "north_star.softmax"(%5) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  "north_star.return"(%7) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%8) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
}) : (tensor<1x128xf32>) -> tensor<1x128xf32>


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357a520) {
      %21 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'north_star.return' op must be the last operation in the parent block
'north_star.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
^bb0(%arg0: !north_star.ns_tensor<2x128xf32,0>):
  %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %1 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %3 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %7 = "builtin.unrealized_conversion_cast"(%6) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %9 = "builtin.unrealized_conversion_cast"(%8) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg4: tensor<1x128xf32>):
    %31 = "north_star.tensor_to_ns_tensor"(%arg4) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %32 = "builtin.unrealized_conversion_cast"(%31) : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %33 = "tensor.empty"() : () -> tensor<1x128xf32>
    %34 = "linalg.softmax"(%32, %33) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %35 = "north_star.softmax"(%31) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %36 = "tensor.empty"() : () -> tensor<1x128xf32>
    %37 = "linalg.softmax"(%34, %36) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %38 = "north_star.softmax"(%35) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%37) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%38) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %11 = "north_star.device_kernel"(%6) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg3: !north_star.ns_tensor<1x128xf32,0>):
    %29 = "north_star.softmax"(%arg3) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    %30 = "north_star.softmax"(%29) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
    "north_star.return"(%30) : (!north_star.ns_tensor<1x128xf32,0>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,0>) -> !north_star.ns_tensor<1x128xf32,0>
  %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %22 = "builtin.unrealized_conversion_cast"(%21) : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "north_star.softmax"(%21) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %26 = "tensor.empty"() : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%24, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %28 = "north_star.softmax"(%25) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%28) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "north_star.device_kernel"(%8) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<1x128xf32,1>):
    %19 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
    "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,1>) -> ()
  }) : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>
  %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %15 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5ebc63575fd0) {
  %19 = "north_star.softmax"(%arg1) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.softmax'(0x5ebc63576060) {
  %20 = "north_star.softmax"(%19) <{axis = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5ebc635760e0) {
  "north_star.return"(%20) : (!north_star.ns_tensor<1x128xf32,1>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc63564610) {
  %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63576170) {
  %15 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635554d0) {
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc6356de00) {
  %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x5ebc635647b0) {
  "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63527580) {
  %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//
ImplicitTypeIDRegistry::lookupOrInsert(mlir::north_star::detail::NSTensorToTensorOpGenericAdaptorBase::Properties)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a720)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a640)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357acb0)
** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357ad70)
** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357ae30)
** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357aef0)
run out: ConvertNorthStarToLinalgPass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::DestinationStyleOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::DestinationStyleOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::linalg::AggregatedOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::linalg::AggregatedOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::TilingInterface::Trait<mlir::TypeID::get() [with Trait = mlir::TilingInterface::Trait]::Empty>)
// -----// IR Dump After ConvertNorthStarToLinalgPass (convert-north-satr-to-linalg) //----- //
module @NorthStar {
  func.func @main(%arg0: !north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0> attributes {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} {
    %0 = "north_star.buffer"(%arg0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %1 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %2 = "north_star.tensor_to_ns_tensor"(%1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %3 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %4 = "north_star.tensor_to_ns_tensor"(%3) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %5 = "north_star.buffer"(%2, %4) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%0, %5) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %6 = "north_star.get_tensor"(%5) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %7 = "north_star.ns_tensor_to_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %8 = "north_star.get_tensor"(%5) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %9 = "north_star.ns_tensor_to_tensor"(%8) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %10 = "north_star.device_kernel"(%7) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
      %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
      %21 = tensor.empty() : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %23 = tensor.empty() : tensor<1x128xf32>
      %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %24 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %12 = "north_star.device_kernel"(%9) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg1: tensor<1x128xf32>):
      %19 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
      %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
      %21 = tensor.empty() : tensor<1x128xf32>
      %22 = linalg.softmax dimension(1) ins(%20 : tensor<1x128xf32>) outs(%21 : tensor<1x128xf32>) -> tensor<1x128xf32>
      %23 = tensor.empty() : tensor<1x128xf32>
      %24 = linalg.softmax dimension(1) ins(%22 : tensor<1x128xf32>) outs(%23 : tensor<1x128xf32>) -> tensor<1x128xf32>
      north_star.return %24 : tensor<1x128xf32>
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %14 = "north_star.buffer"(%11, %13) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %15 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %17 = "north_star.buffer"(%16) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%14, %17) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %18 = "north_star.get_tensor"(%17) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    return %18 : !north_star.ns_tensor<2x128xf32,0>
  }
}


run in NorthStarLegalizePass

//===-------------------------------------------===//
Legalizing operation : 'builtin.module'(0x5ebc63524120) {
  * Fold {
  } -> FAILURE : unable to fold
} -> FAILURE : no matched legalization pattern
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.func'(0x5ebc63527d30) {
  * Fold {
  } -> FAILURE : unable to fold

  * Pattern : 'func.func -> ()' {
Trying to match "{anonymous}::FuncFuncOpRerewriterPattern"
    ** Insert  : 'func.func'(0x5ebc63578a70)
    ** Insert Block into : 'func.func'(0x5ebc63578a70)
    ** Insert  : 'north_star.buffer'(0x5ebc6357b9d0)
    ** Insert  : 'tensor.empty'(0x5ebc6357bf40)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc63576e50)
    ** Insert  : 'tensor.empty'(0x5ebc6353cbf0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bfe0)
    ** Insert  : 'north_star.buffer'(0x5ebc63579e40)
    ** Insert  : 'north_star.scatter'(0x5ebc6357b960)
    ** Insert  : 'north_star.get_tensor'(0x5ebc6356f9e0)
    ** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357bb00)
    ** Insert  : 'north_star.get_tensor'(0x5ebc6357a930)
    ** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a470)
    ** Insert  : 'north_star.device_kernel'(0x5ebc635789f0)
    ** Insert Block into : 'north_star.device_kernel'(0x5ebc635789f0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc63577c20)
    ** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc63577c90)
    ** Insert  : 'tensor.empty'(0x5ebc63577d00)
    ** Insert  : 'linalg.softmax'(0x5ebc63577d70)
    ** Insert  : 'tensor.empty'(0x5ebc63577de0)
    ** Insert  : 'linalg.softmax'(0x5ebc63577e50)
    ** Insert  : 'north_star.return'(0x5ebc6357bdb0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bd50)
    ** Insert  : 'north_star.device_kernel'(0x5ebc63578960)
    ** Insert Block into : 'north_star.device_kernel'(0x5ebc63578960)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357cf20)
    ** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357cf90)
    ** Insert  : 'tensor.empty'(0x5ebc6357d000)
    ** Insert  : 'linalg.softmax'(0x5ebc6357d070)
    ** Insert  : 'tensor.empty'(0x5ebc6357d0e0)
    ** Insert  : 'linalg.softmax'(0x5ebc6357d150)
    ** Insert  : 'north_star.return'(0x5ebc6357d1b0)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc63574430)
    ** Insert  : 'north_star.buffer'(0x5ebc635744a0)
    ** Insert  : 'tensor.empty'(0x5ebc63573840)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc635738b0)
    ** Insert  : 'north_star.buffer'(0x5ebc6357b5b0)
    ** Insert  : 'north_star.gather'(0x5ebc6357b7e0)
    ** Insert  : 'north_star.get_tensor'(0x5ebc6357b620)
    ** Insert  : 'func.return'(0x5ebc6357a840)
    ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357df60)
    ** Replace : 'func.func'(0x5ebc63527d30)
"{anonymous}::FuncFuncOpRerewriterPattern" result 1

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5ebc6357b9d0) {
      %32 = "north_star.buffer"(%31) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'func.func'(0x5ebc63578a70) {
    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5ebc6357b9d0) {
      %32 = "north_star.buffer"(%31) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc6357bf40) {
      %33 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576e50) {
      %34 = "north_star.tensor_to_ns_tensor"(%33) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc6353cbf0) {
      %35 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bfe0) {
      %36 = "north_star.tensor_to_ns_tensor"(%35) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5ebc63579e40) {
      %37 = "north_star.buffer"(%34, %36) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.scatter'(0x5ebc6357b960) {
      "north_star.scatter"(%32, %37) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5ebc6356f9e0) {
      %38 = "north_star.get_tensor"(%37) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357bb00) {
      %39 = "north_star.ns_tensor_to_tensor"(%38) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5ebc6357a930) {
      %40 = "north_star.get_tensor"(%37) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a470) {
      %41 = "north_star.ns_tensor_to_tensor"(%40) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5ebc635789f0) {
      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpToFuncPattern"
        ** Insert  : 'func.call'(0x5ebc63581a20)
        ** Insert Block into : 'func.func'(0x5ebc63581900)
        ** Insert  : 'north_star.tensor_to_ns_tensor'(0x5ebc6357d8e0)
        ** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc6357fb60)
        ** Insert  : 'tensor.empty'(0x5ebc6357fbd0)
        ** Insert  : 'linalg.softmax'(0x5ebc6357fc40)
        ** Insert  : 'tensor.empty'(0x5ebc6357fcb0)
        ** Insert  : 'linalg.softmax'(0x5ebc6357fd20)
        ** Insert  : 'north_star.return'(0x5ebc6357fd80)
        ** Replace : 'north_star.device_kernel'(0x5ebc635789f0)
"{anonymous}::DeviceKernelOpToFuncPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'func.func'(0x5ebc63581900) {
        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'func.call'(0x5ebc63581a20) {
          %48 = "func.call"(%45) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357d8e0) {
          %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357fb60) {
          %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6357fbd0) {
          %2 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357fc40) {
          %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'tensor.empty'(0x5ebc6357fcb0) {
          %4 = "tensor.empty"() : () -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'linalg.softmax'(0x5ebc6357fd20) {
          %5 = "linalg.softmax"(%3, %4) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//

        //===-------------------------------------------===//
        Legalizing operation : 'north_star.return'(0x5ebc6357fd80) {
          "north_star.return"(%5) : (tensor<1x128xf32>) -> ()

          * Fold {
          } -> FAILURE : unable to fold

          * Pattern : 'north_star.return -> ()' {
Trying to match "{anonymous}::ReturnOpToFuncPattern"
            ** Insert  : 'func.return'(0x5ebc63573420)
            ** Replace : 'north_star.return'(0x5ebc6357fd80)
"{anonymous}::ReturnOpToFuncPattern" result 1

            //===-------------------------------------------===//
            Legalizing operation : 'func.return'(0x5ebc63573420) {
              "func.return"(%5) : (tensor<1x128xf32>) -> ()

            } -> SUCCESS : operation marked legal by the target
            //===-------------------------------------------===//
          } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'func.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{function_type = (tensor<1x128xf32>) -> tensor<1x128xf32>, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
^bb0(%arg0: tensor<1x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %2 = "tensor.empty"() : () -> tensor<1x128xf32>
  %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  %4 = "tensor.empty"() : () -> tensor<1x128xf32>
  %5 = "linalg.softmax"(%3, %4) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
  "func.return"(%5) : (tensor<1x128xf32>) -> ()
  "north_star.return"(%5) : (tensor<1x128xf32>) -> ()
}) {device_kernel} : () -> ()


        } -> SUCCESS
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
type of return operand 0 ('!north_star.ns_tensor<2x128xf32,0>') doesn't match function result type ('tensor<2x128xf32>') in function @main
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{arg_attrs = [{func.device_id = 0 : i64}], function_type = (tensor<2x128xf32>) -> tensor<2x128xf32>, sym_name = "main"}> ({
^bb0(%arg0: tensor<2x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %2 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %11 = "func.call"(%8) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %27 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %28 = "north_star.ns_tensor_to_tensor"(%27) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %29 = "tensor.empty"() : () -> tensor<1x128xf32>
    %30 = "linalg.softmax"(%28, %29) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %31 = "tensor.empty"() : () -> tensor<1x128xf32>
    %32 = "linalg.softmax"(%30, %31) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%32) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %14 = "north_star.device_kernel"(%10) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %21 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %22 = "north_star.ns_tensor_to_tensor"(%21) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %23 = "tensor.empty"() : () -> tensor<1x128xf32>
    %24 = "linalg.softmax"(%22, %23) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %25 = "tensor.empty"() : () -> tensor<1x128xf32>
    %26 = "linalg.softmax"(%24, %25) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%26) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "north_star.tensor_to_ns_tensor"(%14) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %16 = "north_star.buffer"(%13, %15) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %17 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %19 = "north_star.buffer"(%18) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%16, %19) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %20 = "north_star.get_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%20) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) : () -> ()


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63577c20) {
      %64 = "north_star.tensor_to_ns_tensor"(%arg6) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc63577c90) {
      %65 = "north_star.ns_tensor_to_tensor"(%64) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc63577d00) {
      %66 = "tensor.empty"() : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x5ebc63577d70) {
      %67 = "linalg.softmax"(%65, %66) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc63577de0) {
      %68 = "tensor.empty"() : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x5ebc63577e50) {
      %69 = "linalg.softmax"(%67, %68) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5ebc6357bdb0) {
      "north_star.return"(%69) : (tensor<1x128xf32>) -> ()

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bd50) {
      %50 = "north_star.tensor_to_ns_tensor"(%49) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.device_kernel'(0x5ebc63578960) {
      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'north_star.device_kernel -> ()' {
Trying to match "{anonymous}::DeviceKernelOpToFuncPattern"
        ** Insert  : 'func.call'(0x5ebc635811c0)
        ** Replace : 'north_star.device_kernel'(0x5ebc63578960)
"{anonymous}::DeviceKernelOpToFuncPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'func.call'(0x5ebc635811c0) {
          %51 = "func.call"(%47) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
type of return operand 0 ('!north_star.ns_tensor<2x128xf32,0>') doesn't match function result type ('tensor<2x128xf32>') in function @main
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{arg_attrs = [{func.device_id = 0 : i64}], function_type = (tensor<2x128xf32>) -> tensor<2x128xf32>, sym_name = "main"}> ({
^bb0(%arg0: tensor<2x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %2 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %11 = "func.call"(%8) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %28 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %29 = "north_star.ns_tensor_to_tensor"(%28) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %30 = "tensor.empty"() : () -> tensor<1x128xf32>
    %31 = "linalg.softmax"(%29, %30) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %32 = "tensor.empty"() : () -> tensor<1x128xf32>
    %33 = "linalg.softmax"(%31, %32) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%33) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %14 = "func.call"(%10) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "north_star.device_kernel"(%10) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %22 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %23 = "north_star.ns_tensor_to_tensor"(%22) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %24 = "tensor.empty"() : () -> tensor<1x128xf32>
    %25 = "linalg.softmax"(%23, %24) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %26 = "tensor.empty"() : () -> tensor<1x128xf32>
    %27 = "linalg.softmax"(%25, %26) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%27) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %17 = "north_star.buffer"(%13, %16) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %18 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %19 = "north_star.tensor_to_ns_tensor"(%18) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %20 = "north_star.buffer"(%19) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%17, %20) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %21 = "north_star.get_tensor"(%20) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  "func.return"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) : () -> ()


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357cf20) {
      %59 = "north_star.tensor_to_ns_tensor"(%arg5) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357cf90) {
      %60 = "north_star.ns_tensor_to_tensor"(%59) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc6357d000) {
      %61 = "tensor.empty"() : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x5ebc6357d070) {
      %62 = "linalg.softmax"(%60, %61) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc6357d0e0) {
      %63 = "tensor.empty"() : () -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'linalg.softmax'(0x5ebc6357d150) {
      %64 = "linalg.softmax"(%62, %63) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.return'(0x5ebc6357d1b0) {
      "north_star.return"(%64) : (tensor<1x128xf32>) -> ()

    } -> SUCCESS : operation marked 'ignored' during conversion
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63574430) {
      %53 = "north_star.tensor_to_ns_tensor"(%52) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5ebc635744a0) {
      %54 = "north_star.buffer"(%50, %53) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'tensor.empty'(0x5ebc63573840) {
      %55 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635738b0) {
      %56 = "north_star.tensor_to_ns_tensor"(%55) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.buffer'(0x5ebc6357b5b0) {
      %57 = "north_star.buffer"(%56) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.gather'(0x5ebc6357b7e0) {
      "north_star.gather"(%54, %57) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.get_tensor'(0x5ebc6357b620) {
      %58 = "north_star.get_tensor"(%57) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'func.return'(0x5ebc6357a840) {
      "func.return"(%58) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

      * Fold {
      } -> FAILURE : unable to fold

      * Pattern : 'func.return -> ()' {
Trying to match "{anonymous}::FuncReturnOpRerewriterPattern"
        ** Insert  : 'func.return'(0x5ebc6357c120)
        ** Replace : 'func.return'(0x5ebc6357a840)
"{anonymous}::FuncReturnOpRerewriterPattern" result 1

        //===-------------------------------------------===//
        Legalizing operation : 'func.return'(0x5ebc6357c120) {
          "func.return"(%59) : (tensor<2x128xf32>) -> ()

        } -> SUCCESS : operation marked legal by the target
        //===-------------------------------------------===//
      } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'func.return' op must be the last operation in the parent block
mlir-asm-printer: 'func.func' failed to verify and will be printed in generic form
"func.func"() <{arg_attrs = [{func.device_id = 0 : i64}], function_type = (tensor<2x128xf32>) -> tensor<2x128xf32>, sym_name = "main"}> ({
^bb0(%arg0: tensor<2x128xf32>):
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  %2 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
  %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %4 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
  %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
  %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
  %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
  %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
  %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
  %11 = "func.call"(%8) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %12 = "north_star.device_kernel"(%8) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg2: tensor<1x128xf32>):
    %29 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %30 = "north_star.ns_tensor_to_tensor"(%29) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %31 = "tensor.empty"() : () -> tensor<1x128xf32>
    %32 = "linalg.softmax"(%30, %31) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %33 = "tensor.empty"() : () -> tensor<1x128xf32>
    %34 = "linalg.softmax"(%32, %33) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%34) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %13 = "north_star.tensor_to_ns_tensor"(%12) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %14 = "func.call"(%10) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %15 = "north_star.device_kernel"(%10) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg1: tensor<1x128xf32>):
    %23 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %24 = "north_star.ns_tensor_to_tensor"(%23) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %25 = "tensor.empty"() : () -> tensor<1x128xf32>
    %26 = "linalg.softmax"(%24, %25) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %27 = "tensor.empty"() : () -> tensor<1x128xf32>
    %28 = "linalg.softmax"(%26, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "north_star.return"(%28) : (tensor<1x128xf32>) -> ()
  }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
  %17 = "north_star.buffer"(%13, %16) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
  %18 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
  %19 = "north_star.tensor_to_ns_tensor"(%18) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
  %20 = "north_star.buffer"(%19) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
  "north_star.gather"(%17, %20) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
  %21 = "north_star.get_tensor"(%20) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
  %22 = "builtin.unrealized_conversion_cast"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>
  "func.return"(%22) : (tensor<2x128xf32>) -> ()
  "func.return"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
}) : () -> ()


    } -> SUCCESS
    //===-------------------------------------------===//

    //===-------------------------------------------===//
    Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357df60) {
      %37 = "north_star.tensor_to_ns_tensor"(%arg4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

    } -> SUCCESS : operation marked legal by the target
    //===-------------------------------------------===//
  } -> SUCCESS : pattern applied successfully
// *** IR Dump After Pattern Application ***
'func.return' op must be the last operation in the parent block
'func.return' op must be the last operation in the parent block
mlir-asm-printer: 'builtin.module' failed to verify and will be printed in generic form
"builtin.module"() <{sym_name = "NorthStar"}> ({
  "func.func"() <{arg_attrs = [{func.device_id = 0 : i64}], function_type = (tensor<2x128xf32>) -> tensor<2x128xf32>, sym_name = "main"}> ({
  ^bb0(%arg4: tensor<2x128xf32>):
    %37 = "north_star.tensor_to_ns_tensor"(%arg4) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %38 = "north_star.buffer"(%37) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %39 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %40 = "north_star.tensor_to_ns_tensor"(%39) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %41 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
    %42 = "north_star.tensor_to_ns_tensor"(%41) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %43 = "north_star.buffer"(%40, %42) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%38, %43) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %44 = "north_star.get_tensor"(%43) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %45 = "north_star.ns_tensor_to_tensor"(%44) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %46 = "north_star.get_tensor"(%43) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %47 = "north_star.ns_tensor_to_tensor"(%46) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %48 = "func.call"(%45) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %49 = "north_star.device_kernel"(%45) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg6: tensor<1x128xf32>):
      %66 = "north_star.tensor_to_ns_tensor"(%arg6) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
      %67 = "north_star.ns_tensor_to_tensor"(%66) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
      %68 = "tensor.empty"() : () -> tensor<1x128xf32>
      %69 = "linalg.softmax"(%67, %68) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %70 = "tensor.empty"() : () -> tensor<1x128xf32>
      %71 = "linalg.softmax"(%69, %70) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%71) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %50 = "north_star.tensor_to_ns_tensor"(%49) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %51 = "func.call"(%47) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %52 = "north_star.device_kernel"(%47) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg5: tensor<1x128xf32>):
      %60 = "north_star.tensor_to_ns_tensor"(%arg5) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
      %61 = "north_star.ns_tensor_to_tensor"(%60) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
      %62 = "tensor.empty"() : () -> tensor<1x128xf32>
      %63 = "linalg.softmax"(%61, %62) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %64 = "tensor.empty"() : () -> tensor<1x128xf32>
      %65 = "linalg.softmax"(%63, %64) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%65) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %53 = "north_star.tensor_to_ns_tensor"(%52) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %54 = "north_star.buffer"(%50, %53) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %55 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
    %56 = "north_star.tensor_to_ns_tensor"(%55) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %57 = "north_star.buffer"(%56) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%54, %57) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %58 = "north_star.get_tensor"(%57) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    %59 = "builtin.unrealized_conversion_cast"(%58) : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>
    "func.return"(%59) : (tensor<2x128xf32>) -> ()
    "func.return"(%58) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
  }) : () -> ()
  "func.func"() <{function_type = (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.ns_tensor<2x128xf32,0>, sym_name = "main"}> ({
  ^bb0(%arg1: !north_star.ns_tensor<2x128xf32,0>):
    %6 = "north_star.buffer"(%arg1) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %7 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>
    %8 = "north_star.tensor_to_ns_tensor"(%7) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %9 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>
    %10 = "north_star.tensor_to_ns_tensor"(%9) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %11 = "north_star.buffer"(%8, %10) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%6, %11) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %12 = "north_star.get_tensor"(%11) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %13 = "north_star.ns_tensor_to_tensor"(%12) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %14 = "north_star.get_tensor"(%11) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %15 = "north_star.ns_tensor_to_tensor"(%14) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %16 = "north_star.device_kernel"(%13) <{device_id = 0 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg3: tensor<1x128xf32>):
      %31 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
      %32 = "north_star.ns_tensor_to_tensor"(%31) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
      %33 = "tensor.empty"() : () -> tensor<1x128xf32>
      %34 = "linalg.softmax"(%32, %33) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %35 = "tensor.empty"() : () -> tensor<1x128xf32>
      %36 = "linalg.softmax"(%34, %35) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%36) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %18 = "north_star.device_kernel"(%15) <{device_id = 1 : i64, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
    ^bb0(%arg2: tensor<1x128xf32>):
      %25 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
      %26 = "north_star.ns_tensor_to_tensor"(%25) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
      %27 = "tensor.empty"() : () -> tensor<1x128xf32>
      %28 = "linalg.softmax"(%26, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      %29 = "tensor.empty"() : () -> tensor<1x128xf32>
      %30 = "linalg.softmax"(%28, %29) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
      "north_star.return"(%30) : (tensor<1x128xf32>) -> ()
    }) : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %19 = "north_star.tensor_to_ns_tensor"(%18) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %20 = "north_star.buffer"(%17, %19) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %21 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>
    %22 = "north_star.tensor_to_ns_tensor"(%21) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %23 = "north_star.buffer"(%22) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%20, %23) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %24 = "north_star.get_tensor"(%23) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    "func.return"(%24) : (!north_star.ns_tensor<2x128xf32,0>) -> ()
  }) {dp_attr = #north_star.DP<DP = 2 : 0, 1>, host_func} : () -> ()
  "func.func"() <{function_type = (tensor<1x128xf32>) -> tensor<1x128xf32>, sym_name = "softmax_1_128_softmax_1_128_fused_kernel"}> ({
  ^bb0(%arg0: tensor<1x128xf32>):
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %2 = "tensor.empty"() : () -> tensor<1x128xf32>
    %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    %4 = "tensor.empty"() : () -> tensor<1x128xf32>
    %5 = "linalg.softmax"(%3, %4) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>
    "func.return"(%5) : (tensor<1x128xf32>) -> ()
    "north_star.return"(%5) : (tensor<1x128xf32>) -> ()
  }) {device_kernel} : () -> ()
}) : () -> ()


} -> SUCCESS
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc6356ed50) {
  %6 = "north_star.buffer"(%arg1) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63564880) {
  %7 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635761e0) {
  %8 = "north_star.tensor_to_ns_tensor"(%7) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63576ae0) {
  %9 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576b50) {
  %10 = "north_star.tensor_to_ns_tensor"(%9) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc63576be0) {
  %11 = "north_star.buffer"(%8, %10) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.scatter'(0x5ebc63576c80) {
  "north_star.scatter"(%6, %11) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63576d30) {
  %12 = "north_star.get_tensor"(%11) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357ad70) {
  %13 = "north_star.ns_tensor_to_tensor"(%12) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63576dc0) {
  %14 = "north_star.get_tensor"(%11) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a640) {
  %15 = "north_star.ns_tensor_to_tensor"(%14) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5ebc6356e3c0) {
} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63578b40) {
  %31 = "north_star.tensor_to_ns_tensor"(%arg3) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357acb0) {
  %32 = "north_star.ns_tensor_to_tensor"(%31) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc6357bc30) {
  %33 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5ebc6357bca0) {
  %34 = "linalg.softmax"(%32, %33) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc6357be20) {
  %35 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5ebc6357be90) {
  %36 = "linalg.softmax"(%34, %35) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5ebc635746c0) {
  "north_star.return"(%36) : (tensor<1x128xf32>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357ae30) {
  %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.device_kernel'(0x5ebc6357a190) {
} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357a520) {
  %25 = "north_star.tensor_to_ns_tensor"(%arg2) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a720) {
  %26 = "north_star.ns_tensor_to_tensor"(%25) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc6353cb80) {
  %27 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5ebc6357b740) {
  %28 = "linalg.softmax"(%26, %27) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc6357b850) {
  %29 = "tensor.empty"() : () -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'linalg.softmax'(0x5ebc6357b8c0) {
  %30 = "linalg.softmax"(%28, %29) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.return'(0x5ebc63579ec0) {
  "north_star.return"(%30) : (tensor<1x128xf32>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357aef0) {
  %19 = "north_star.tensor_to_ns_tensor"(%18) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc63564610) {
  %20 = "north_star.buffer"(%17, %19) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'tensor.empty'(0x5ebc63576170) {
  %21 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635554d0) {
  %22 = "north_star.tensor_to_ns_tensor"(%21) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.buffer'(0x5ebc6356de00) {
  %23 = "north_star.buffer"(%22) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.gather'(0x5ebc635647b0) {
  "north_star.gather"(%20, %23) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'north_star.get_tensor'(0x5ebc63527580) {
  %24 = "north_star.get_tensor"(%23) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> SUCCESS : operation marked legal by the target
//===-------------------------------------------===//

//===-------------------------------------------===//
Legalizing operation : 'func.return'(0x5ebc63527cb0) {
  "func.return"(%24) : (!north_star.ns_tensor<2x128xf32,0>) -> ()

} -> SUCCESS : operation marked 'ignored' during conversion
//===-------------------------------------------===//
** Insert  : 'north_star.ns_tensor_to_tensor'(0x5ebc635802c0)
run out: NorthStarLegalizePass
ImplicitTypeIDRegistry::lookupOrInsert(mlir::CallOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::CallOpInterface::Trait]::Empty>)
ImplicitTypeIDRegistry::lookupOrInsert(mlir::SymbolUserOpInterface::Trait<mlir::TypeID::get() [with Trait = mlir::SymbolUserOpInterface::Trait]::Empty>)
// -----// IR Dump After NorthStarLegalizePass (north-star-legalize) //----- //
module @NorthStar {
  func.func @main(%arg0: tensor<2x128xf32> {func.device_id = 0 : i64}) -> tensor<2x128xf32> {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %11 = call @softmax_1_128_softmax_1_128_fused_kernel(%8) {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %13 = call @softmax_1_128_softmax_1_128_fused_kernel(%10) {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %15 = "north_star.buffer"(%12, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %16 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %18 = "north_star.buffer"(%17) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%15, %18) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %19 = "north_star.get_tensor"(%18) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>
    return %20 : tensor<2x128xf32>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %2 = tensor.empty() : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %4 = tensor.empty() : tensor<1x128xf32>
    %5 = linalg.softmax dimension(1) ins(%3 : tensor<1x128xf32>) outs(%4 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %5 : tensor<1x128xf32>
  }
}



//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63578a70) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357df60) {
  %6 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6357b9d0) {
  %7 = "north_star.buffer"(%6) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357bf40) {
  %8 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576e50) {
  %9 = "north_star.tensor_to_ns_tensor"(%8) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6353cbf0) {
  %10 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bfe0) {
  %11 = "north_star.tensor_to_ns_tensor"(%10) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63579e40) {
  %12 = "north_star.buffer"(%9, %11) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5ebc6357b960) {
  "north_star.scatter"(%7, %12) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6356f9e0) {
  %13 = "north_star.get_tensor"(%12) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357bb00) {
  %14 = "north_star.ns_tensor_to_tensor"(%13) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6357a930) {
  %15 = "north_star.get_tensor"(%12) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a470) {
  %16 = "north_star.ns_tensor_to_tensor"(%15) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.call'(0x5ebc63581a20) {
  %17 = "func.call"(%14) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bd50) {
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.call'(0x5ebc635811c0) {
  %19 = "func.call"(%16) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63574430) {
  %20 = "north_star.tensor_to_ns_tensor"(%19) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc635744a0) {
  %21 = "north_star.buffer"(%18, %20) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63573840) {
  %22 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635738b0) {
  %23 = "north_star.tensor_to_ns_tensor"(%22) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6357b5b0) {
  %24 = "north_star.buffer"(%23) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5ebc6357b7e0) {
  "north_star.gather"(%21, %24) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6357b620) {
  %25 = "north_star.get_tensor"(%24) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc635802c0) {
  %26 = "north_star.ns_tensor_to_tensor"(%25) <{device_id = 0 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc6357c120) {
  "func.return"(%26) : (tensor<2x128xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63581900) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357d8e0) {
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357fb60) {
  %1 = "north_star.ns_tensor_to_tensor"(%0) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
    ** Replace : 'north_star.ns_tensor_to_tensor'(0x5ebc6357fb60)
    ** Modified: 'linalg.softmax'(0x5ebc6357fc40)
    ** Erase   : 'north_star.ns_tensor_to_tensor'(0x5ebc6357fb60)
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 1
  } -> success : pattern applied successfully
// *** IR Dump After Pattern Application ***
func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
  %1 = tensor.empty() : tensor<1x128xf32>
  %2 = linalg.softmax dimension(1) ins(%arg0 : tensor<1x128xf32>) outs(%1 : tensor<1x128xf32>) -> tensor<1x128xf32>
  %3 = tensor.empty() : tensor<1x128xf32>
  %4 = linalg.softmax dimension(1) ins(%2 : tensor<1x128xf32>) outs(%3 : tensor<1x128xf32>) -> tensor<1x128xf32>
  return %4 : tensor<1x128xf32>
}


} -> success : pattern matched
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357d8e0) {
  %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>

  ** Erase   : 'north_star.tensor_to_ns_tensor'(0x5ebc6357d8e0)
} -> success : operation is trivially dead
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63581900) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357fbd0) {
  %0 = "tensor.empty"() : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'linalg.softmax'(0x5ebc6357fc40) {
  %1 = "linalg.softmax"(%arg0, %0) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>


  * Pattern FoldTensorCastProducerOp : 'linalg.softmax -> ()' {
Trying to match "FoldTensorCastProducerOp"
"FoldTensorCastProducerOp" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357fcb0) {
  %2 = "tensor.empty"() : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'linalg.softmax'(0x5ebc6357fd20) {
  %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>


  * Pattern FoldTensorCastProducerOp : 'linalg.softmax -> ()' {
Trying to match "FoldTensorCastProducerOp"
"FoldTensorCastProducerOp" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63573420) {
  "func.return"(%3) : (tensor<1x128xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63578a70) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357df60) {
  %4 = "north_star.tensor_to_ns_tensor"(%arg1) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6357b9d0) {
  %5 = "north_star.buffer"(%4) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357bf40) {
  %6 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63576e50) {
  %7 = "north_star.tensor_to_ns_tensor"(%6) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6353cbf0) {
  %8 = "tensor.empty"() {device_id = 1 : i64} : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bfe0) {
  %9 = "north_star.tensor_to_ns_tensor"(%8) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc63579e40) {
  %10 = "north_star.buffer"(%7, %9) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.scatter'(0x5ebc6357b960) {
  "north_star.scatter"(%5, %10) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6356f9e0) {
  %11 = "north_star.get_tensor"(%10) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357bb00) {
  %12 = "north_star.ns_tensor_to_tensor"(%11) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6357a930) {
  %13 = "north_star.get_tensor"(%10) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc6357a470) {
  %14 = "north_star.ns_tensor_to_tensor"(%13) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.call'(0x5ebc63581a20) {
  %15 = "func.call"(%12) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc6357bd50) {
  %16 = "north_star.tensor_to_ns_tensor"(%15) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.call'(0x5ebc635811c0) {
  %17 = "func.call"(%14) <{callee = @softmax_1_128_softmax_1_128_fused_kernel}> {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc63574430) {
  %18 = "north_star.tensor_to_ns_tensor"(%17) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc635744a0) {
  %19 = "north_star.buffer"(%16, %18) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc63573840) {
  %20 = "tensor.empty"() {device_id = 0 : i64} : () -> tensor<2x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.tensor_to_ns_tensor'(0x5ebc635738b0) {
  %21 = "north_star.tensor_to_ns_tensor"(%20) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>


  * Pattern mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate : 'north_star.tensor_to_ns_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate"
"mlir::north_star::{anonymous}::TensorToNSTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.buffer'(0x5ebc6357b5b0) {
  %22 = "north_star.buffer"(%21) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.gather'(0x5ebc6357b7e0) {
  "north_star.gather"(%19, %22) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.get_tensor'(0x5ebc6357b620) {
  %23 = "north_star.get_tensor"(%22) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'north_star.ns_tensor_to_tensor'(0x5ebc635802c0) {
  %24 = "north_star.ns_tensor_to_tensor"(%23) <{device_id = 0 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>


  * Pattern mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate : 'north_star.ns_tensor_to_tensor -> ()' {
Trying to match "mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate"
"mlir::north_star::{anonymous}::NSTensorToTensorOpEliminate" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc6357c120) {
  "func.return"(%24) : (tensor<2x128xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.func'(0x5ebc63581900) {
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357fbd0) {
  %0 = "tensor.empty"() : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'linalg.softmax'(0x5ebc6357fc40) {
  %1 = "linalg.softmax"(%arg0, %0) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>


  * Pattern FoldTensorCastProducerOp : 'linalg.softmax -> ()' {
Trying to match "FoldTensorCastProducerOp"
"FoldTensorCastProducerOp" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'tensor.empty'(0x5ebc6357fcb0) {
  %2 = "tensor.empty"() : () -> tensor<1x128xf32>


  * Pattern {anonymous}::ReplaceEmptyTensorStaticShapeDims : 'tensor.empty -> ()' {
Trying to match "{anonymous}::ReplaceEmptyTensorStaticShapeDims"
"{anonymous}::ReplaceEmptyTensorStaticShapeDims" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'linalg.softmax'(0x5ebc6357fd20) {
  %3 = "linalg.softmax"(%1, %2) <{dimension = 1 : i64}> : (tensor<1x128xf32>, tensor<1x128xf32>) -> tensor<1x128xf32>


  * Pattern FoldTensorCastProducerOp : 'linalg.softmax -> ()' {
Trying to match "FoldTensorCastProducerOp"
"FoldTensorCastProducerOp" result 0
  } -> failure : pattern failed to match
} -> failure : pattern failed to match
//===-------------------------------------------===//

//===-------------------------------------------===//
Processing operation : 'func.return'(0x5ebc63573420) {
  "func.return"(%3) : (tensor<1x128xf32>) -> ()

} -> failure : pattern failed to match
//===-------------------------------------------===//
// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module @NorthStar {
  func.func @main(%arg0: tensor<2x128xf32> {func.device_id = 0 : i64}) -> tensor<2x128xf32> {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %11 = call @softmax_1_128_softmax_1_128_fused_kernel(%8) {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %13 = call @softmax_1_128_softmax_1_128_fused_kernel(%10) {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %15 = "north_star.buffer"(%12, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %16 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %18 = "north_star.buffer"(%17) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%15, %18) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %19 = "north_star.get_tensor"(%18) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>
    return %20 : tensor<2x128xf32>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = tensor.empty() : tensor<1x128xf32>
    %1 = linalg.softmax dimension(1) ins(%arg0 : tensor<1x128xf32>) outs(%0 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %2 = tensor.empty() : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %3 : tensor<1x128xf32>
  }
}


initializing north_star
register north_star  Type
register north_star  Attr
register north_star  Op
module @NorthStar {
  func.func @main(%arg0: tensor<2x128xf32> {func.device_id = 0 : i64}) -> tensor<2x128xf32> {
    %0 = "north_star.tensor_to_ns_tensor"(%arg0) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %1 = "north_star.buffer"(%0) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    %2 = tensor.empty() {device_id = 0 : i64} : tensor<1x128xf32>
    %3 = "north_star.tensor_to_ns_tensor"(%2) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %4 = tensor.empty() {device_id = 1 : i64} : tensor<1x128xf32>
    %5 = "north_star.tensor_to_ns_tensor"(%4) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %6 = "north_star.buffer"(%3, %5) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    "north_star.scatter"(%1, %6) : (!north_star.buffer<0>, !north_star.buffer<0, 1>) -> ()
    %7 = "north_star.get_tensor"(%6) <{device_id = 0 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,0>
    %8 = "north_star.ns_tensor_to_tensor"(%7) <{device_id = 0 : i64}> : (!north_star.ns_tensor<1x128xf32,0>) -> tensor<1x128xf32>
    %9 = "north_star.get_tensor"(%6) <{device_id = 1 : i64}> : (!north_star.buffer<0, 1>) -> !north_star.ns_tensor<1x128xf32,1>
    %10 = "north_star.ns_tensor_to_tensor"(%9) <{device_id = 1 : i64}> : (!north_star.ns_tensor<1x128xf32,1>) -> tensor<1x128xf32>
    %11 = call @softmax_1_128_softmax_1_128_fused_kernel(%8) {device_id = 0 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %12 = "north_star.tensor_to_ns_tensor"(%11) <{device_id = 0 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,0>
    %13 = call @softmax_1_128_softmax_1_128_fused_kernel(%10) {device_id = 1 : i64, device_kernel} : (tensor<1x128xf32>) -> tensor<1x128xf32>
    %14 = "north_star.tensor_to_ns_tensor"(%13) <{device_id = 1 : i64}> : (tensor<1x128xf32>) -> !north_star.ns_tensor<1x128xf32,1>
    %15 = "north_star.buffer"(%12, %14) : (!north_star.ns_tensor<1x128xf32,0>, !north_star.ns_tensor<1x128xf32,1>) -> !north_star.buffer<0, 1>
    %16 = tensor.empty() {device_id = 0 : i64} : tensor<2x128xf32>
    %17 = "north_star.tensor_to_ns_tensor"(%16) <{device_id = 0 : i64}> : (tensor<2x128xf32>) -> !north_star.ns_tensor<2x128xf32,0>
    %18 = "north_star.buffer"(%17) : (!north_star.ns_tensor<2x128xf32,0>) -> !north_star.buffer<0>
    "north_star.gather"(%15, %18) : (!north_star.buffer<0, 1>, !north_star.buffer<0>) -> ()
    %19 = "north_star.get_tensor"(%18) <{device_id = 0 : i64}> : (!north_star.buffer<0>) -> !north_star.ns_tensor<2x128xf32,0>
    %20 = "north_star.ns_tensor_to_tensor"(%19) <{device_id = 0 : i64}> : (!north_star.ns_tensor<2x128xf32,0>) -> tensor<2x128xf32>
    return %20 : tensor<2x128xf32>
  }
  func.func @softmax_1_128_softmax_1_128_fused_kernel(%arg0: tensor<1x128xf32>) -> tensor<1x128xf32> attributes {device_kernel} {
    %0 = tensor.empty() : tensor<1x128xf32>
    %1 = linalg.softmax dimension(1) ins(%arg0 : tensor<1x128xf32>) outs(%0 : tensor<1x128xf32>) -> tensor<1x128xf32>
    %2 = tensor.empty() : tensor<1x128xf32>
    %3 = linalg.softmax dimension(1) ins(%1 : tensor<1x128xf32>) outs(%2 : tensor<1x128xf32>) -> tensor<1x128xf32>
    return %3 : tensor<1x128xf32>
  }
}

destroying north_star
